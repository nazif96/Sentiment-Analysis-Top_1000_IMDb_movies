{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c55925",
   "metadata": {},
   "source": [
    "## **Deep Learning avec LSTM (m√©moire √† long terme) :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46bc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from pathlib import Path\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52efa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Watch Time</th>\n",
       "      <th>Movie Rating</th>\n",
       "      <th>Metascore of movie</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>142</td>\n",
       "      <td>9.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>28.34</td>\n",
       "      <td>27,77,378</td>\n",
       "      <td>Over the course of several years, two convicts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>175</td>\n",
       "      <td>9.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>134.97</td>\n",
       "      <td>19,33,588</td>\n",
       "      <td>Don Vito Corleone, head of a mafia family, dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>534.86</td>\n",
       "      <td>27,54,087</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                Movie Name Year of Release  Watch Time  \\\n",
       "0           0  The Shawshank Redemption            1994         142   \n",
       "1           1             The Godfather            1972         175   \n",
       "2           2           The Dark Knight            2008         152   \n",
       "\n",
       "   Movie Rating  Metascore of movie   Gross      Votes  \\\n",
       "0           9.3                82.0   28.34  27,77,378   \n",
       "1           9.2               100.0  134.97  19,33,588   \n",
       "2           9.0                84.0  534.86  27,54,087   \n",
       "\n",
       "                                         Description  \n",
       "0  Over the course of several years, two convicts...  \n",
       "1  Don Vito Corleone, head of a mafia family, dec...  \n",
       "2  When the menace known as the Joker wreaks havo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = Path().resolve().parent\n",
    "DATA_DIR = BASE_DIR / 'Data' \n",
    "\n",
    "df = pd.read_csv(DATA_DIR / 'Top_1000_IMDb_movies.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b10dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unnamed:_0', 'movie_name', 'year_of_release', 'watch_time',\n",
       "       'movie_rating', 'metascore_of_movie', 'gross', 'votes', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cad41",
   "metadata": {},
   "source": [
    "## **VADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7043e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NAZIFOU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove Stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    " \n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "#Clean Text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    text = ' '.join(text.split()) \n",
    "    return text\n",
    "\n",
    "#stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "df['description'] = df['description'].astype(str)\n",
    "df['description'] = df['description'].apply(lambda x: remove_stopwords(x))\n",
    "df['description'] = df['description'].apply(lambda x:clean_text(x))\n",
    "df['description'] = df['description'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4518557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           description VADER_Sentiment_Label\n",
      "591  after break childhood sweetheart young man fin...              Positive\n",
      "887  three young irish women struggl maintain spiri...              Positive\n",
      "59   two high school sweetheart meet reunion year r...              Positive\n",
      "239  renton deepli immers edinburgh drug scene tri ...              Positive\n",
      "731  a mistaken deliveri mumbai s famous effici lun...              Negative\n",
      "699  a hot temper farm labor convinc woman love mar...              Positive\n",
      "487  back sex safe pleasur busi busi boom idealist ...              Positive\n",
      "379  a disillus colleg graduat find torn older love...              Positive\n",
      "868  a young boy name kubo must locat magic suit ar...              Negative\n",
      "814  a video game villain want hero set fulfil drea...              Negative\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores\n",
    "df['VADER_Sentiment'] = df['description'].apply(lambda text: sia.polarity_scores(text)['compound'])\n",
    "\n",
    "# Categorize sentiment\n",
    "df['VADER_Sentiment_Label'] = df['VADER_Sentiment'].apply(lambda score: 'Positive' if score > 0 else ('Negative' if score < 0 else 'Neutral'))\n",
    "\n",
    "# Print sample results\n",
    "print(df[['description', 'VADER_Sentiment_Label']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3219b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Diviser l'ensemble de donn√©es en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['description'], df['VADER_Sentiment_Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df393ee",
   "metadata": {},
   "source": [
    "## **Entra√Ænement du mod√®le LSTM (m√©moire √† long terme)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "607f15a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordre des classes : ['Negative' 'Neutral' 'Positive']\n",
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.4770 - loss: 1.0619 - val_accuracy: 0.4350 - val_loss: 1.0467\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.5137 - loss: 1.0045 - val_accuracy: 0.4850 - val_loss: 0.9971\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.6700 - loss: 0.6721 - val_accuracy: 0.5800 - val_loss: 1.1755\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.8432 - loss: 0.3680 - val_accuracy: 0.6050 - val_loss: 1.0959\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9538 - loss: 0.1692 - val_accuracy: 0.5900 - val_loss: 1.2655\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5161 - loss: 0.9643\n",
      "‚úÖ Test Accuracy: 0.4850\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Pr√©traitement des donn√©es\n",
    "# -----------------------------\n",
    "# Tokenisation\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=200, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=200, padding='post', truncating='post')\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Encodage des labels (textes ‚Üí entiers ‚Üí one-hot)\n",
    "# -----------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)   # 'Negative', 'Neutral', 'Positive' ‚Üí 0, 1, 2\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train_encoded, num_classes=3)\n",
    "y_test_categorical = to_categorical(y_test_encoded, num_classes=3)\n",
    "\n",
    "print(\"Ordre des classes :\", label_encoder.classes_)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Construction du mod√®le\n",
    "# -----------------------------\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))  # Pas besoin de input_length\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compilation\n",
    "# -----------------------------\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Entra√Ænement avec EarlyStopping\n",
    "# -----------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_padded,\n",
    "    y_train_categorical,\n",
    "    validation_data=(X_test_padded, y_test_categorical),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. √âvaluation finale\n",
    "# -----------------------------\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test_categorical)\n",
    "print(f\"‚úÖ Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a38414",
   "metadata": {},
   "source": [
    "**Ce qui va bien :**\n",
    "- L'entra√Ænement se passe bien, pas d'erreur üëç\n",
    "- Le mod√®le apprend clairement : accuracy monte jusqu‚Äô√† 0.95 sur le train\n",
    "- Le mod√®le est capable de capter les classes, donc les embeddings + LSTM fonctionnent \n",
    "\n",
    "\n",
    "**Probl√®me de surapprentissage (overfitting)**\n",
    "- Train accuracy : 0.95\n",
    "- Val accuracy : plafonne autour de 0.48‚Äì0.60\n",
    "- Val loss augmente ‚Üí le mod√®le m√©morise le training set, mais g√©n√©ralise mal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6725724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sauvegarde du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cebce034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 1. Sauvegarder le mod√®le\n",
    "model.save(\"sentiment_model.h5\")\n",
    "\n",
    "# 2. Sauvegarder le tokenizer\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# 3. Sauvegarder le label encoder\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
